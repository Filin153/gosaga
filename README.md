# github.com/Filin153/gosaga (v1)

## EN
Saga helper with Postgres storage and Kafka transport. `NewSaga`:
- runs migration from `v1/pg-migration.sql`
- wires PG repos
- starts Kafka reader
- exposes aliases/helpers so you import everything from `github.com/Filin153/gosaga/v1`.
- accepts `logLevel slog.Leveler` to set slog level for all gosaga logs

### Requirements
- PostgreSQL tables from `v1/pg-migration.sql`
- `pgxpool.Pool`
- Kafka + `sarama.Config`
- Migration creates PK columns with identity; if you change schema, keep defaults/sequences.

### Interfaces & exports
- `WorkerInterface`:
  - `Worker(ctx context.Context, task *SagaTask, sess Session) error`
  - `DlqWorker(ctx context.Context, task *SagaTask, sess Session) error`
- Built-in outbound handler: `NewOutWorker(kafka.Writer)` provides `Worker/DlqWorker`.
- Aliases in this package: `SagaMsg`, `SagaTask`, `TaskStatus`, `Session`, `TaskRepository`, `DLQRepository`
- Kafka helpers: `NewKafkaWriter(...)`, `NewKafkaReader(...)`
- Task/DLQ repositories: PG impl (`storage/database/pg`), swappable

### Example
```go
package main

import (
	"context"
	"log"
	"log/slog"
	"os/signal"
	"syscall"

	gosaga "github.com/Filin153/gosaga/v1"
	"github.com/IBM/sarama"
	"github.com/jackc/pgx/v5/pgxpool"
)

// inbound worker example
type demoInWorker struct{}

func (w *demoInWorker) Worker(ctx context.Context, task *gosaga.SagaTask, sess gosaga.Session) error {
	// do something with task.Data inside sess (pgx.Tx)
	return nil
}
func (w *demoInWorker) DlqWorker(ctx context.Context, task *gosaga.SagaTask, sess gosaga.Session) error {
	return w.Worker(ctx, task, sess)
}

func main() {
	ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
	defer stop()

	pool, err := pgxpool.New(ctx, "postgres://postgres:postgres@postgres/postgres")
	if err != nil {
		log.Fatal(err)
	}

	kafkaConf := sarama.NewConfig()
	kafkaConf.Version = sarama.V3_6_0_0

	saga, err := gosaga.NewSaga(ctx, pool, "consumer-group", []string{"input-topic"}, []string{"kafka:9092"}, kafkaConf, slog.LevelDebug)
	if err != nil {
		log.Fatal(err)
	}

	// outWorker publishes to Kafka using built-in OutWorker
	kafkaWriter, _ := gosaga.NewKafkaWriter([]string{"kafka:9092"}, kafkaConf)
	outWorker := gosaga.NewOutWorker(kafkaWriter)

	if err := saga.RunWorkers(ctx, 4, outWorker, &demoInWorker{}); err != nil {
		log.Fatal(err)
	}

	// write outgoing task to out-topic
	_ = saga.Write(ctx, &gosaga.SagaMsg{Key: "k", Value: []byte(`{"foo":"bar"}`), Topic: "test-1"}, nil, func() {})
	_ = saga.Write(ctx, &gosaga.SagaMsg{Key: "k", Value: []byte(`{"foo":"bar"}`), Topic: "test-2"}, &gosaga.SagaMsg{Key: "rollback-k", Value: []byte(`{"foo":"rollback_data"}`), Topic: "test-2-rollback_data"}, func() {})

	// block until signal
	<-ctx.Done()
	pool.Close()
	stop()
}

```

### Key methods
- `RunWorkers(ctx, limiter, outWorker, inWorker)` – starts in/out + DLQ loops (limiter per stream)
- `Write(ctx, msg, rollbackMsg, rollbackFunc)` – sync insert to out-task table; on error calls rollbackFunc
- `AsyncWrite(ctx, msg, rollbackMsg, rollbackFunc)` – async version; rollbackFunc on early error

### Tables (see `v1/pg-migration.sql`)
- `go_saga_in_task` / `go_saga_out_task`
- `go_saga_dlq_in_task` / `go_saga_dlq_out_task`

### Statuses (`domain.TaskStatus`)
`wait`, `reserved`, `work`, `ready`, `error`, `rollback`, `error_rollback_none`

Notes:
- Tasks in `wait` are atomically moved to `reserved` when fetched; stale reservations (default 120s) are re-picked.
- DLQ tasks in `error` are reserved the same way before being retried.

### Mocks
`mocks/kafka`, `mocks/database`, `mocks/core/v1` (mockery/testify) for writer/reader/repos/worker.

---

## RU
Хелпер для саг с хранением в Postgres и транспортом Kafka. `NewSaga`:
- автоматически запускает миграцию `v1/pg-migration.sql`
- поднимает PG-репозитории
- стартует Kafka reader
- экспортирует алиасы/хелперы, чтобы импортировать всё из `github.com/Filin153/gosaga/v1`.
- принимает `logLevel slog.Leveler`, задающий уровень логов для gosaga

### Требования
- PostgreSQL с таблицами из `v1/pg-migration.sql`
- `pgxpool.Pool`
- Kafka + `sarama.Config`
- В миграции PK колонки создаются с `GENERATED BY DEFAULT AS IDENTITY`; если правите схему, сохраняйте авто-генерацию ID.

### Интерфейсы и экспорты
- `WorkerInterface`:
  - `Worker(ctx context.Context, task *SagaTask, sess Session) error`
  - `DlqWorker(ctx context.Context, task *SagaTask, sess Session) error`
- Готовый обработчик исходящих задач: `NewOutWorker(kafka.Writer)` реализует `Worker/DlqWorker`.
- Алиасы: `SagaMsg`, `SagaTask`, `TaskStatus`, `Session`, `TaskRepository`, `DLQRepository`
- Kafka-хелперы: `NewKafkaWriter(...)`, `NewKafkaReader(...)`
- Репозитории задач/DLQ: PG-реализация (`storage/database/pg`), можно подменять

### Пример
```go
package main

import (
	"context"
	"log"
	"log/slog"
	"os/signal"
	"syscall"

	gosaga "github.com/Filin153/gosaga/v1"
	"github.com/IBM/sarama"
	"github.com/jackc/pgx/v5/pgxpool"
)

// inbound worker example
type demoInWorker struct{}

func (w *demoInWorker) Worker(ctx context.Context, task *gosaga.SagaTask, sess gosaga.Session) error {
	// do something with task.Data inside sess (pgx.Tx)
	return nil
}
func (w *demoInWorker) DlqWorker(ctx context.Context, task *gosaga.SagaTask, sess gosaga.Session) error {
	return w.Worker(ctx, task, sess)
}

func main() {
	ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
	defer stop()

	pool, err := pgxpool.New(ctx, "postgres://postgres:postgres@postgres/postgres")
	if err != nil {
		log.Fatal(err)
	}

	kafkaConf := sarama.NewConfig()
	kafkaConf.Version = sarama.V3_6_0_0

	saga, err := gosaga.NewSaga(ctx, pool, "consumer-group", []string{"input-topic"}, []string{"kafka:9092"}, kafkaConf, slog.LevelDebug)
	if err != nil {
		log.Fatal(err)
	}

	// outWorker publishes to Kafka using built-in OutWorker
	kafkaWriter, _ := gosaga.NewKafkaWriter([]string{"kafka:9092"}, kafkaConf)
	outWorker := gosaga.NewOutWorker(kafkaWriter)

	if err := saga.RunWorkers(ctx, 4, outWorker, &demoInWorker{}); err != nil {
		log.Fatal(err)
	}

	// write outgoing task to out-topic
	_ = saga.Write(ctx, &gosaga.SagaMsg{Key: "k", Value: []byte(`{"foo":"bar"}`), Topic: "test-1"}, nil, func() {})
	_ = saga.Write(ctx, &gosaga.SagaMsg{Key: "k", Value: []byte(`{"foo":"bar"}`), Topic: "test-2"}, &gosaga.SagaMsg{Key: "rollback-k", Value: []byte(`{"foo":"rollback_data"}`), Topic: "test-2-rollback_data"}, func() {})

	// block until signal
	<-ctx.Done()
	pool.Close()
	stop()
}

```

### Основные методы
- `RunWorkers(ctx, limiter, outWorker, inWorker)` – запускает циклы обработки in/out и DLQ (лимитер на поток)
- `Write(ctx, msg, rollbackMsg, rollbackFunc)` – синхронно пишет в out-таблицу; при ошибке вызывает rollbackFunc
- `AsyncWrite(ctx, msg, rollbackMsg, rollbackFunc)` – асинхронная запись; rollbackFunc при ранней ошибке

### Таблицы
- `go_saga_in_task` / `go_saga_out_task`
- `go_saga_dlq_in_task` / `go_saga_dlq_out_task`

### Статусы (`domain.TaskStatus`)
`wait`, `reserved`, `work`, `ready`, `error`, `rollback`, `error_rollback_none`

Примечания:
- Задачи в `wait` при выдаче переводятся в `reserved`; если 120 секунд не сдвинулись дальше, их выберут повторно.
- DLQ-задачи в `error` резервируются аналогично перед повторной отправкой.

### Моки
`mocks/kafka`, `mocks/database`, `mocks/core/v1` — mockery/testify для Writer/Reader и репозиториев/воркера.
